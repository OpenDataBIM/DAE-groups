{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DAEgroups_OpenDataBIM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as ET\n",
        "from slugify import slugify\n",
        "\n",
        "# Determining the path where the files are located and creating a new folder\n",
        "pathn = '/content/drive/MyDrive/BIMJSON/TGA2'\n",
        "\n",
        "##############################################################################\n",
        "\n",
        "# Sets the type for geometry grouping\n",
        "# Category, Сomment, Type or any other property of any element\n",
        "\n",
        "search_parameter = 'Type'\n",
        "\n",
        "##############################################################################\n",
        "\n",
        "# Main function for grouping data and saving a file\n",
        "def crtable(filename):\n",
        "    filenamep = pathn + '/' + filename\n",
        "    df = pd.read_csv(filenamep, low_memory=False)\n",
        "    filedae = pathn + '/' + filename[:-8]+'dae'\n",
        "    ### grouping by element types for different formats\n",
        "    #if 'ifc' in filenamep:\n",
        "    #  search_parameter = 'Type'\n",
        "    #else:\n",
        "    #  search_parameter = 'Type Name'\n",
        "\n",
        "    # Determination of the number of elements in groups\n",
        "    df2= df.groupby([search_parameter])['Volume'].agg(['count'])\n",
        "    dfallpar = pd.DataFrame()  \n",
        "    df['Unnamed: 0'] = df['Unnamed: 0'].astype(str)\n",
        "    comma = lambda x: ', '.join(x.unique())\n",
        "    df3 = df.groupby([search_parameter]) .agg({'Unnamed: 0': comma})\n",
        "    \n",
        "    # Collecting data into one dataframe\n",
        "    dfallpar = pd.concat([df2, df3], axis=1)\n",
        "    dfallpar.rename(columns=({ 'Unnamed: 0': 'Id´s', 'count': 'Amount'}), inplace=True,)\n",
        "    \n",
        "    dfallpar['type'] = dfallpar.index\n",
        "    #dfallpar.insert(0, 'Group Key', dfallpar['type'].apply(slugify))\n",
        "    \n",
        "    # Start sorting geometry from DAE file\n",
        "    # Formation of a data tree from the DAE format\n",
        "    daegrpath = pathn + '/' + 'DAEgroups_' + filename[:-9] \n",
        "    try:\n",
        "      os.mkdir(daegrpath)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    # If the ID of an element from the group_ids_str list that was found earlier matches,\n",
        "    # all elements with this ID are found in the DAE file, and all other elements are deleted\n",
        "    filedaearr = []\n",
        "\n",
        "    for index, row in dfallpar.iterrows():\n",
        "      fileObject = open(filedae, \"r\")\n",
        "      treeq = ET.parse(fileObject)\n",
        "      root = treeq.getroot()\n",
        "      ET.register_namespace(\"\", \"http://www.collada.org/2005/11/COLLADASchema\")\n",
        "      geom_list = []\n",
        "      group_ids_str = []\n",
        "      group_ids_str = re.findall(r'\\d+', row['Id´s'])\n",
        "      for node in root.findall('.//{http://www.collada.org/2005/11/COLLADASchema}node'):\n",
        "          tree = treeq\n",
        "          if node.attrib['id'] in group_ids_str:\n",
        "            try:\n",
        "              url = list(node)[0].get('url')\n",
        "              geom_list.append(url[1:])\n",
        "            except:\n",
        "              pass\n",
        "          else:\n",
        "              try:\n",
        "                  nd = node.find(\n",
        "                      '{http://www.collada.org/2005/11/COLLADASchema}instance_geometry')\n",
        "                  node.remove(nd)\n",
        "              except:\n",
        "                  0\n",
        "      for geomet in root.findall('.//{http://www.collada.org/2005/11/COLLADASchema}geometry'):\n",
        "            if geomet.attrib['id'] in geom_list:\n",
        "                0\n",
        "            else:\n",
        "                try:\n",
        "                  md = geomet.find(\n",
        "                      '{http://www.collada.org/2005/11/COLLADASchema}mesh')\n",
        "                  geomet.remove(md)\n",
        "                except:\n",
        "                  pass\n",
        "      # Formation of a new name for the DAE file with grouped elements\n",
        "      # words_pattern = '[a-zA-Z10-9]+'\n",
        "      invalid = '<>:\"/\\|?* '\n",
        "      for char in invalid:\n",
        "        index = index.replace(char, '')\n",
        "      regw = index + '.dae'\n",
        "      filedaena = daegrpath + '/' + regw\n",
        "      with open(filedaena, 'w') as f:\n",
        "          tree.write(f, encoding='unicode')\n",
        "\n",
        "# Function execution cycle for all CSV files in the folder\n",
        "for filename in os.listdir(pathn):\n",
        "  if filename.endswith(\"csv\"): \n",
        "      crtable(filename)\n",
        "      \n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "# Saving data to a ZIP file for downloading to a computer\n",
        "#!zip -r /content/file.zip /content/rvt"
      ],
      "metadata": {
        "id": "021FgXtrp_JO"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8YNHmeXsCjG",
        "outputId": "c2b9cec2-ab1e-4636-961c-bf60bedd9f1b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    }
  ]
}